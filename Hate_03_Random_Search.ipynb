{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hate_03_Random_Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOQ30kDBYQQp"
      },
      "source": [
        "## Search for Hyperparameters Using Random Search\n",
        "Here, we use Random Search in Keras Tuner to find the best hyperparameters for RNN (Recurrent Neural Network) model later. The parameters include the number of neurons, the number of internal states in LSTM, dropout rate and learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN6uPB4JEE-A",
        "outputId": "93a6ffa5-9700-4c68-9a6f-6fff75808959"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCkzRtyhYQQ2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import kerastuner as kt\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmZ8ZYDP2oos"
      },
      "source": [
        "Load data from Google Colab or local computer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run from Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('drive/MyDrive/Colab/Hate/tweets_malay.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xr5Y3z0vUk7",
        "outputId": "92c79b96-e99a-4f05-a571-c3ec1a9c6c49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JH6Xuo8k5vBT",
        "outputId": "df3b0801-e070-44dd-c5b6-5cfb0578f383"
      },
      "source": [
        "df.columns = [\"text\", \"label\"]\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4c025ee-6305-46a1-b3d1-9273a50ccafd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haha babi dia punya tidak menyabar macam ada 1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ini namanya pns kontol banyak gaya emosi aing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pukimak punya jantan trick baru dia guna   bud...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pantat apa eh jual karipap inti basi nak menia...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ini warga emas ke oku le frontliner apa kepent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1855</th>\n",
              "      <td>temen gw banget sudah tau doi nya toxic banget...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1856</th>\n",
              "      <td>kau komen lebai la mende la vid lucah pn kau l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1857</th>\n",
              "      <td>pastu kau tahu kain dalam eh babi aku dah paka...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1858</th>\n",
              "      <td>sekarang ramai babi dah pandai drive kete atas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1859</th>\n",
              "      <td>awak ada potensi hilman   ya babi ada potensi ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1860 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4c025ee-6305-46a1-b3d1-9273a50ccafd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4c025ee-6305-46a1-b3d1-9273a50ccafd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4c025ee-6305-46a1-b3d1-9273a50ccafd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     haha babi dia punya tidak menyabar macam ada 1...      1\n",
              "1     ini namanya pns kontol banyak gaya emosi aing ...      1\n",
              "2     pukimak punya jantan trick baru dia guna   bud...      1\n",
              "3     pantat apa eh jual karipap inti basi nak menia...      1\n",
              "4     ini warga emas ke oku le frontliner apa kepent...      1\n",
              "...                                                 ...    ...\n",
              "1855  temen gw banget sudah tau doi nya toxic banget...      0\n",
              "1856  kau komen lebai la mende la vid lucah pn kau l...      1\n",
              "1857  pastu kau tahu kain dalam eh babi aku dah paka...      1\n",
              "1858  sekarang ramai babi dah pandai drive kete atas...      1\n",
              "1859  awak ada potensi hilman   ya babi ada potensi ...      1\n",
              "\n",
              "[1860 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNjvtUBuvpQ",
        "outputId": "58662aef-760f-4121-a2ed-58d726ecb1dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1188\n",
              "0     672\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu2lXPJu2msC"
      },
      "source": [
        "Load the word embeddings from Malaya social media corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rXwwl21pI1i"
      },
      "source": [
        "import joblib\n",
        "\n",
        "def load_word_vector(file = 'drive/MyDrive/Colab/Hate/word_vector.pkl'):\n",
        "  from os import path\n",
        "\n",
        "  if path.exists(file):    \n",
        "    word_vector = joblib.load(file)\n",
        "  else:\n",
        "    !pip install malaya\n",
        "    import malaya\n",
        "\n",
        "    vocab, embedded = malaya.wordvector.load(model = 'socialmedia')\n",
        "    wv = malaya.wordvector.WordVector(embedded, vocab)\n",
        "    word_vector = {word: wv.get_vector_by_name(word) for word in wv.words}\n",
        "    \n",
        "  return word_vector\n",
        "\n",
        "word_vector = load_word_vector()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPRb0TrU2xvM"
      },
      "source": [
        "Tokenize all words and build the word embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N__UdzX-alie"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 123)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apq0qE-GpUYV"
      },
      "source": [
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(df['text'])\n",
        "vocab_size = len(t.word_index) + 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di50U6qWpUIu"
      },
      "source": [
        "X_train_seq = t.texts_to_sequences(X_train)\n",
        "X_test_seq = t.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences so each sequence is the same length\n",
        "X_train_seq_padded = pad_sequences(X_train_seq, 50)\n",
        "X_test_seq_padded = pad_sequences(X_test_seq, 50)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJmtygXQpT4u"
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 256))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = word_vector.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnHIjA2PYQQ7"
      },
      "source": [
        "Define range of hyperparameters and the RNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0TSTpmzkksZ"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMXeQwd6HbX"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  lstm = hp.Int('lstm', min_value=32, max_value=256, step=32, default=64)\n",
        "  # lstm = 64\n",
        "\n",
        "  hp_units = hp.Int('units', min_value=4, max_value=32, step=4, default=8)\n",
        "  # hp_units = 8\n",
        "\n",
        "  dropout = hp.Float('dropout', min_value=0.1, max_value=0.9, step=0.1, default=0.5)\n",
        "  # dropout = 0.5\n",
        "  \n",
        "  # hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.003, 0.001, 0.0003, 0.0001, 0.00003])\n",
        "  hp_learning_rate = 0.001\n",
        "\n",
        "  model.add(Embedding(vocab_size, 256, weights=[embedding_matrix], input_length=50, trainable=False))\n",
        "\n",
        "  model.add(LSTM(lstm, dropout = dropout, recurrent_dropout = dropout))\n",
        "  model.add(Dense(hp_units, activation = 'relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD7RoCPT6vqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8801c7-423b-4255-b3ae-f05e53044716"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=25,\n",
        "    executions_per_trial=1,\n",
        "    directory='drive/MyDrive/Colab/Hate/randomsearch',\n",
        "    overwrite = True,\n",
        "    project_name='Hate Speech')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09cuaTlw9Dpo",
        "outputId": "312a6189-c727-47bb-bdbe-788a0ae9d8c3"
      },
      "source": [
        "tuner.search_space_summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "lstm (Int)\n",
            "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
            "units (Int)\n",
            "{'default': 8, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': None}\n",
            "dropout (Float)\n",
            "{'default': 0.5, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfca7iZy3ORo"
      },
      "source": [
        "Search for best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1WQF4-NCdPO"
      },
      "source": [
        "seed(123)\n",
        "set_seed(234)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfwHgwBD6wE1",
        "outputId": "e1259282-b785-410a-ec01-263715b9c19d"
      },
      "source": [
        "# tuner.search(X_train_seq_padded, y_train, epochs=10, validation_split=0.2)\n",
        "tuner.search(X_train_seq_padded, y_train, epochs=10, validation_data = (X_test_seq_padded, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 Complete [00h 02m 38s]\n",
            "val_accuracy: 0.7419354915618896\n",
            "\n",
            "Best val_accuracy So Far: 0.7715053558349609\n",
            "Total elapsed time: 01h 16m 30s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tav1mYs9273"
      },
      "source": [
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFQw739i-KBy",
        "outputId": "ee5dd423-3828-4a92-c175-ea541ef23a4f"
      },
      "source": [
        "best_hps.values"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropout': 0.4, 'lstm': 128, 'units': 32}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMy9otZe3So4"
      },
      "source": [
        "Show the search results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XDZY2FV9JRE",
        "outputId": "85e99f47-afef-40fa-e167-c0505738d3f5"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in drive/MyDrive/Colab/Hate/randomsearch/Hate Speech\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 128\n",
            "units: 32\n",
            "dropout: 0.4\n",
            "Score: 0.7715053558349609\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 224\n",
            "units: 28\n",
            "dropout: 0.30000000000000004\n",
            "Score: 0.7580645084381104\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 64\n",
            "units: 28\n",
            "dropout: 0.2\n",
            "Score: 0.7553763389587402\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 160\n",
            "units: 8\n",
            "dropout: 0.30000000000000004\n",
            "Score: 0.7553763389587402\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 64\n",
            "units: 20\n",
            "dropout: 0.6\n",
            "Score: 0.7526881694793701\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 64\n",
            "units: 24\n",
            "dropout: 0.1\n",
            "Score: 0.7526881694793701\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 96\n",
            "units: 24\n",
            "dropout: 0.4\n",
            "Score: 0.75\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 160\n",
            "units: 12\n",
            "dropout: 0.4\n",
            "Score: 0.7446236610412598\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 96\n",
            "units: 24\n",
            "dropout: 0.30000000000000004\n",
            "Score: 0.7419354915618896\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm: 32\n",
            "units: 12\n",
            "dropout: 0.4\n",
            "Score: 0.7419354915618896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muooz2pc3ZU_"
      },
      "source": [
        "Rebuild RNN model using the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRXsyNv6wTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41679eda-ab8e-4d60-d88b-2b8cd86bd8a0"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 20 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "# history = model.fit(X_train_seq_padded, y_train, batch_size = 32, epochs=20, validation_split=0.2)\n",
        "history = model.fit(X_train_seq_padded, y_train, batch_size = 32, epochs=20, validation_data = (X_test_seq_padded, y_test))\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "47/47 [==============================] - 18s 332ms/step - loss: 0.6525 - accuracy: 0.6169 - val_loss: 0.5992 - val_accuracy: 0.7124\n",
            "Epoch 2/20\n",
            "47/47 [==============================] - 15s 316ms/step - loss: 0.6238 - accuracy: 0.6687 - val_loss: 0.5650 - val_accuracy: 0.7124\n",
            "Epoch 3/20\n",
            "47/47 [==============================] - 15s 321ms/step - loss: 0.6034 - accuracy: 0.6788 - val_loss: 0.5585 - val_accuracy: 0.7070\n",
            "Epoch 4/20\n",
            "47/47 [==============================] - 15s 321ms/step - loss: 0.5712 - accuracy: 0.7003 - val_loss: 0.5186 - val_accuracy: 0.7204\n",
            "Epoch 5/20\n",
            "47/47 [==============================] - 15s 319ms/step - loss: 0.5664 - accuracy: 0.7030 - val_loss: 0.5147 - val_accuracy: 0.7366\n",
            "Epoch 6/20\n",
            "47/47 [==============================] - 15s 320ms/step - loss: 0.5616 - accuracy: 0.7036 - val_loss: 0.5366 - val_accuracy: 0.7285\n",
            "Epoch 7/20\n",
            "47/47 [==============================] - 15s 322ms/step - loss: 0.5545 - accuracy: 0.7218 - val_loss: 0.5220 - val_accuracy: 0.7177\n",
            "Epoch 8/20\n",
            "47/47 [==============================] - 15s 320ms/step - loss: 0.5326 - accuracy: 0.7352 - val_loss: 0.5280 - val_accuracy: 0.7204\n",
            "Epoch 9/20\n",
            "47/47 [==============================] - 15s 325ms/step - loss: 0.5070 - accuracy: 0.7487 - val_loss: 0.5203 - val_accuracy: 0.7204\n",
            "Epoch 10/20\n",
            "47/47 [==============================] - 15s 324ms/step - loss: 0.5013 - accuracy: 0.7547 - val_loss: 0.5409 - val_accuracy: 0.7204\n",
            "Epoch 11/20\n",
            "47/47 [==============================] - 15s 318ms/step - loss: 0.5003 - accuracy: 0.7560 - val_loss: 0.5340 - val_accuracy: 0.7151\n",
            "Epoch 12/20\n",
            "47/47 [==============================] - 15s 320ms/step - loss: 0.4806 - accuracy: 0.7668 - val_loss: 0.5055 - val_accuracy: 0.7366\n",
            "Epoch 13/20\n",
            "47/47 [==============================] - 15s 325ms/step - loss: 0.4679 - accuracy: 0.7735 - val_loss: 0.5605 - val_accuracy: 0.7177\n",
            "Epoch 14/20\n",
            "47/47 [==============================] - 15s 322ms/step - loss: 0.4598 - accuracy: 0.7917 - val_loss: 0.5686 - val_accuracy: 0.6774\n",
            "Epoch 15/20\n",
            "47/47 [==============================] - 15s 320ms/step - loss: 0.4356 - accuracy: 0.7984 - val_loss: 0.5544 - val_accuracy: 0.7043\n",
            "Epoch 16/20\n",
            "47/47 [==============================] - 15s 326ms/step - loss: 0.4281 - accuracy: 0.8031 - val_loss: 0.5322 - val_accuracy: 0.7231\n",
            "Epoch 17/20\n",
            "47/47 [==============================] - 15s 319ms/step - loss: 0.3856 - accuracy: 0.8259 - val_loss: 0.5412 - val_accuracy: 0.7366\n",
            "Epoch 18/20\n",
            "47/47 [==============================] - 15s 317ms/step - loss: 0.3909 - accuracy: 0.8212 - val_loss: 0.5542 - val_accuracy: 0.7124\n",
            "Epoch 19/20\n",
            "47/47 [==============================] - 16s 338ms/step - loss: 0.3914 - accuracy: 0.8259 - val_loss: 0.5596 - val_accuracy: 0.7204\n",
            "Epoch 20/20\n",
            "47/47 [==============================] - 15s 319ms/step - loss: 0.3443 - accuracy: 0.8562 - val_loss: 0.6034 - val_accuracy: 0.7097\n",
            "Best epoch: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q619fF6M8q79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d6e862-167b-48c9-9048-6a93ebd1c3c4"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(X_train_seq_padded, y_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 16s 336ms/step - loss: 0.6561 - accuracy: 0.6252 - val_loss: 0.6172 - val_accuracy: 0.6477\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 12s 329ms/step - loss: 0.6312 - accuracy: 0.6496 - val_loss: 0.6172 - val_accuracy: 0.6309\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 12s 327ms/step - loss: 0.6184 - accuracy: 0.6479 - val_loss: 0.5986 - val_accuracy: 0.6846\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 12s 328ms/step - loss: 0.5858 - accuracy: 0.6857 - val_loss: 0.6044 - val_accuracy: 0.6913\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 12s 326ms/step - loss: 0.5638 - accuracy: 0.7050 - val_loss: 0.5879 - val_accuracy: 0.6879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc802b9ccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ9Kwb3M8-Cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afcf17f0-9619-4d99-e7b0-1ab3df0443ae"
      },
      "source": [
        "eval_result = hypermodel.evaluate(X_test_seq_padded, y_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5287 - accuracy: 0.7124\n",
            "[test loss, test accuracy]: [0.5287325978279114, 0.7123655676841736]\n"
          ]
        }
      ]
    }
  ]
}